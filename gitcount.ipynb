{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySAL Change Log Statistics\n",
    "\n",
    "This notebook generates the summary statistics for use in the 6-month releases of PySAL, which is now (2017-07) a meta package. \n",
    "\n",
    "It assumes the subpackages have been git cloned in a directory below the location of this notebook. It also requires network connectivity for some of the reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from subprocess import check_output\n",
    "try:\n",
    "    from urllib import urlopen\n",
    "except:\n",
    "    from urllib.request import urlopen\n",
    "\n",
    "import ssl\n",
    "import yaml\n",
    "\n",
    "context = ssl._create_unverified_context()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('packages.yml') as package_file:\n",
    "    packages = yaml.load(package_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.path.abspath(os.path.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2017-11-03'\n",
    "since_date = '--since=\"{start}\"'.format(start=start_date)\n",
    "since_date\n",
    "since = datetime.strptime(start_date+\" 0:0:0\", \"%Y-%m-%d %H:%M:%S\")\n",
    "since"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total commits by subpackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = ['git', 'log', '--oneline', since_date]\n",
    "ncommits = len(check_output(cmd).splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = {}\n",
    "total_commits = 0\n",
    "for package in packages:\n",
    "    subpackages = packages[package].split()\n",
    "    for subpackage in subpackages:\n",
    "        os.chdir(CWD)\n",
    "        os.chdir('tmp/{subpackage}'.format(subpackage=subpackage))\n",
    "        ncommits = len(check_output(cmd).splitlines())\n",
    "        total_commits += ncommits\n",
    "        activity[subpackage] = ncommits\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity, total_commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_cmd = ['git', 'log', '--format=* %aN', since_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_global = set()\n",
    "authors = {}\n",
    "for package in packages:\n",
    "    subpackages = packages[package].split()\n",
    "    for subpackage in subpackages:\n",
    "        os.chdir(CWD)\n",
    "        os.chdir('tmp/{subpackage}'.format(subpackage=subpackage))\n",
    "        ncommits = len(check_output(cmd).splitlines())\n",
    "        all_authors = check_output(author_cmd).splitlines()\n",
    "        unique_authors = sorted(set(all_authors))\n",
    "        authors[subpackage] =  unique_authors\n",
    "        authors_global.update(unique_authors)\n",
    "        #total_commits += ncommits\n",
    "        #activity[subpackage] = ncommits\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disaggregate by PR, Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "ISO8601 = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "PER_PAGE = 100\n",
    "element_pat = re.compile(r'<(.+?)>')\n",
    "rel_pat = re.compile(r'rel=[\\'\"](\\w+)[\\'\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_link_header(headers):\n",
    "    link_s = headers.get('link', '')\n",
    "    urls = element_pat.findall(link_s)\n",
    "    rels = rel_pat.findall(link_s)\n",
    "    d = {}\n",
    "    for rel,url in zip(rels, urls):\n",
    "        d[rel] = url\n",
    "    return d\n",
    "\n",
    "def get_paged_request(url):\n",
    "    \"\"\"get a full list, handling APIv3's paging\"\"\"\n",
    "    results = []\n",
    "    while url:\n",
    "        print(\"fetching %s\" % url, file=sys.stderr)\n",
    "        f = urlopen(url)\n",
    "        results.extend(json.load(f))\n",
    "        links = parse_link_header(f.headers)\n",
    "        url = links.get('next')\n",
    "    return results\n",
    "\n",
    "def get_issues(project=\"pysal/pysal\", state=\"closed\", pulls=False):\n",
    "    \"\"\"Get a list of the issues from the Github API.\"\"\"\n",
    "    which = 'pulls' if pulls else 'issues'\n",
    "    url = \"https://api.github.com/repos/%s/%s?state=%s&per_page=%i\" % (project, which, state, PER_PAGE)\n",
    "    return get_paged_request(url)\n",
    "\n",
    "\n",
    "def _parse_datetime(s):\n",
    "    \"\"\"Parse dates in the format returned by the Github API.\"\"\"\n",
    "    if s:\n",
    "        return datetime.strptime(s, ISO8601)\n",
    "    else:\n",
    "        return datetime.fromtimestamp(0)\n",
    "\n",
    "\n",
    "def issues2dict(issues):\n",
    "    \"\"\"Convert a list of issues to a dict, keyed by issue number.\"\"\"\n",
    "    idict = {}\n",
    "    for i in issues:\n",
    "        idict[i['number']] = i\n",
    "    return idict\n",
    "\n",
    "\n",
    "def is_pull_request(issue):\n",
    "    \"\"\"Return True if the given issue is a pull request.\"\"\"\n",
    "    return 'pull_request_url' in issue\n",
    "\n",
    "\n",
    "def issues_closed_since(period=timedelta(days=365), project=\"pysal/pysal\", pulls=False):\n",
    "    \"\"\"Get all issues closed since a particular point in time. period\n",
    "can either be a datetime object, or a timedelta object. In the\n",
    "latter case, it is used as a time before the present.\"\"\"\n",
    "\n",
    "    which = 'pulls' if pulls else 'issues'\n",
    "\n",
    "    if isinstance(period, timedelta):\n",
    "        period = datetime.now() - period\n",
    "    url = \"https://api.github.com/repos/%s/%s?state=closed&sort=updated&since=%s&per_page=%i\" % (project, which, period.strftime(ISO8601), PER_PAGE)\n",
    "    allclosed = get_paged_request(url)\n",
    "    # allclosed = get_issues(project=project, state='closed', pulls=pulls, since=period)\n",
    "    filtered = [i for i in allclosed if _parse_datetime(i['closed_at']) > period]\n",
    "\n",
    "    # exclude rejected PRs\n",
    "    if pulls:\n",
    "        filtered = [ pr for pr in filtered if pr['merged_at'] ]\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def sorted_by_field(issues, field='closed_at', reverse=False):\n",
    "    \"\"\"Return a list of issues sorted by closing date date.\"\"\"\n",
    "    return sorted(issues, key = lambda i:i[field], reverse=reverse)\n",
    "\n",
    "\n",
    "def report(issues, show_urls=False):\n",
    "    \"\"\"Summary report about a list of issues, printing number and title.\n",
    "    \"\"\"\n",
    "    # titles may have unicode in them, so we must encode everything below\n",
    "    if show_urls:\n",
    "        for i in issues:\n",
    "            role = 'ghpull' if 'merged_at' in i else 'ghissue'\n",
    "            print('* :%s:`%d`: %s' % (role, i['number'],\n",
    "                                        i['title'].encode('utf-8')))\n",
    "    else:\n",
    "        for i in issues:\n",
    "            print('* %d: %s' % (i['number'], i['title'].encode('utf-8')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_issues = {}\n",
    "all_pulls = {}\n",
    "total_commits = 0\n",
    "for package in packages:\n",
    "    subpackages = packages[package].split()\n",
    "    for subpackage in subpackages:\n",
    "        prj = 'pysal/{subpackage}'.format(subpackage=subpackage)\n",
    "        os.chdir(CWD)\n",
    "        os.chdir('tmp/{subpackage}'.format(subpackage=subpackage))\n",
    "        #sub_issues = issues_closed_since(project=prj, period=since)\n",
    "        #issues = issues_closed_since(since, project=prj,pulls=False)\n",
    "        pulls = issues_closed_since(since, project=prj,pulls=True)\n",
    "        issues = sorted_by_field(issues, reverse=True)\n",
    "        pulls = sorted_by_field(pulls, reverse=True)\n",
    "        n_issues, n_pulls = map(len, (issues, pulls))\n",
    "        n_total = n_issues + n_pulls\n",
    "        all_issues[subpackage] = n_total, n_pulls\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = all_issues.keys()\n",
    "table = []\n",
    "for sub in subs:\n",
    "    total, pr = all_issues[sub]\n",
    "    row = [sub, activity[sub], total, pr]\n",
    "    table.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame(table, columns=['package', 'commits', 'total issues', 'pulls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
